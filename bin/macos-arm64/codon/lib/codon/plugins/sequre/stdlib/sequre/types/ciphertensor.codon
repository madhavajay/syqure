import operator, secure_operator

from math import inf

from numpy.ndarray import ndarray
from numpy.create import array, zeros
from pickler import pickle, unpickle
from patch import argmin

from sequre.lattiseq.ckks import Ciphertext, Plaintext
from sequre.utils.utils import one_hot_vector
from sequre.constants import (
    HE_MUL_COST_ESTIMATE, HE_ROT_COST_ESTIMATE,
    HE_ENC_COST_ESTIMATE, MHE_MPC_SWITCH_COST_ESTIMATE,
    MPC_BIG_INT_MUL_COST, ENC_ROW, ENC_COL, ENC_DIAG)

from sequre.settings import DEBUG


class Ciphertensor[ctype]:
    _data: list[ctype]
    shape: list[int]
    slots: int
    _chunk_size: int
    _transposed: bool
    _diagonal_contiguous: bool
    _skinny: bool

    _is_broadcast: bool

    def __init__(
            self,
            _data: list[ctype],
            shape: list[int],
            slots: int,
            _transposed: bool,
            _diagonal_contiguous: bool,
            _skinny: bool,
            _is_broadcast: bool):
        self.__init__(_data, shape, slots, _transposed, _diagonal_contiguous, _skinny)
        self._is_broadcast = _is_broadcast
    
    def __init__(
            self,
            _data: list[ctype],
            shape: list[int],
            slots: int,
            _transposed: bool,
            _diagonal_contiguous: bool,
            _skinny: bool):
        self.__init__(_data, shape, slots, _transposed, _diagonal_contiguous)
        self._skinny = _skinny
    
    def __init__(
            self,
            _data: list[ctype],
            shape: list[int],
            slots: int,
            _transposed: bool,
            _diagonal_contiguous: bool):
        self.__init__(_data, shape, slots, _transposed)
        self._diagonal_contiguous = _diagonal_contiguous
    
    def __init__(
            self,
            _data: list[ctype],
            shape: list[int],
            slots: int,
            _transposed: bool):
        self.__init__(_data, shape, slots)
        self._transposed = _transposed
    
    def __init__(
            self,
            _data: list[ctype],
            shape: list[int],
            slots: int):
        self.__init__(shape, slots)
        self._data = _data
    
    def __init__(
            self,
            shape: list[int],
            slots: int):
        self._data = []
        self.shape = shape
        self.slots = slots
        self._is_broadcast = False
        self._reset_chunk_size()
    
    def __bool__(self) -> bool:
        return bool(self._data)
    
    def __repr__(self) -> str:
        return f"""
            Ciphertensor:
            \tShape: {self.shape}
            \tSlots: {self.slots}
            \tTransposed: {self._transposed}
            \tDiagonal order: {self._diagonal_contiguous}
            \t(Ciphertensor elements cannot be printed in a bulk)
        """
    
    def __iter__(self):
        assert not self._transposed, "Not implemented yet: cannot iter transposed ciphertensor"
        assert self.ndim > 1, "Not implemented yet: cannot iter 1-dimensional ciphertensor"
        yield from self._raw_iter()
    
    def _raw_iter(self):
        for i in range(self.shape[0]):
            yield self._get_rows_raw(i)

    def __pickle__(self, jar: Jar, pasteurized: bool):
        pickle(self._skinny, jar, pasteurized)
        if not pasteurized: jar += self._skinny._pickle_size()
        pickle(self._diagonal_contiguous, jar, pasteurized)
        if not pasteurized: jar += self._diagonal_contiguous._pickle_size()
        pickle(self._transposed, jar, pasteurized)
        if not pasteurized: jar += self._transposed._pickle_size()
        pickle(self.slots, jar, pasteurized)
        if not pasteurized: jar += self.slots._pickle_size()
        pickle(self.shape, jar, pasteurized)
        if not pasteurized: jar += self.shape._pickle_size()
        pickle(self._data, jar, pasteurized)
    
    def __unpickle__(jar: Jar, pasteurized: bool) -> Ciphertensor[ctype]:
        _skinny = unpickle(jar, pasteurized, bool)
        if not pasteurized: jar += _skinny._pickle_size()
        _diagonal_contiguous = unpickle(jar, pasteurized, bool)
        if not pasteurized: jar += _diagonal_contiguous._pickle_size()
        _transposed = unpickle(jar, pasteurized, bool)
        if not pasteurized: jar += _transposed._pickle_size()
        slots = unpickle(jar, pasteurized, int)
        if not pasteurized: jar += slots._pickle_size()
        shape = unpickle(jar, pasteurized, list[int])
        if not pasteurized: jar += shape._pickle_size()
        _data = unpickle(jar, pasteurized, List[ctype])

        return Ciphertensor[ctype](
            _data=_data,
            shape=shape,
            slots=slots,
            _transposed=_transposed,
            _diagonal_contiguous=_diagonal_contiguous,
            _skinny=_skinny)
    
    def _pickle_size(self) -> int:
        return (self._skinny._pickle_size() +
                self._diagonal_contiguous._pickle_size() +
                self._transposed._pickle_size() +
                self.slots._pickle_size() +
                self.shape._pickle_size() +
                self._data._pickle_size())
    
    def copy(self, shallow: bool = False) -> Ciphertensor[ctype]:
        return Ciphertensor[ctype](
            _data=self._data if shallow else self._data.copy(),
            shape=self.shape.copy(),
            slots=self.slots,
            _chunk_size=self._chunk_size,
            _transposed=self._transposed,
            _diagonal_contiguous=self._diagonal_contiguous,
            _skinny=self._skinny,
            _is_broadcast=self._is_broadcast)

    def astype(self, t: type) -> Ciphertensor[ctype]:
        # TODO: Add dtype to Ciphertensor
        return self.copy()
    
    # Internal typechecker hack
    @property
    def _internal_type(self) -> float:
        # TODO: Add dtype to Ciphertensor
        return float()

    @property
    def actual_shape(self):
        cs = self.shape.copy()
        
        if self._diagonal_contiguous and self._skinny:
            cs = cs[::-1]
        if self._transposed:
            cs = cs[::-1]

        return cs
    
    @property
    def cipher_shape(self):
        if not self.shape:
            return []
        
        cs = self.shape.copy()
        cs[-1] = (cs[-1] + self.slots - 1) // self.slots
        return cs
    
    @property
    def size(self):
        return Ciphertensor._count(self.shape)

    @property
    def ndim(self):
        return len(self.shape)
    
    @property
    def T(self) -> Ciphertensor[ctype]:
        return Ciphertensor[ctype](
            _data=self._data.copy(),
            shape=self.shape.copy(),
            slots=self.slots,
            _chunk_size=self._chunk_size,
            _transposed=self._transposed ^ True,
            _diagonal_contiguous=self._diagonal_contiguous,
            _skinny=self._skinny)
    
    def I(self, mpc) -> Ciphertensor[ctype]:
        assert self.ndim == 2, "Ciphertensor: cannot get identity matrix from non-2-dimensional ciphertensor"
        m, n = self.shape[::-1] if self._transposed else self.shape
        return Ciphertensor[ctype].enc(mpc, ndarray.diag((m, n), 1.0))
    
    def __getitem__(self, indices) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensor: cannot do getitem without IR pass enabled")
    
    def __setitem__(self, indices, value: Ciphertensor[ctype]):
        raise NotImplementedError("Ciphertensor: cannot do setitem without IR pass enabled")
    
    def __neg__(self: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be negated without IR pass enabled")
    
    def __add__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be added without IR pass enabled")

    def __sub__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be subtracted without IR pass enabled")
    
    def __mul__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be multiplied without IR pass enabled")

    def __matmul__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors matrices cannot be multiplied without IR pass enabled")
    
    def __pow__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be pow-ed without IR pass enabled")

    def __gt__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be compared without IR pass enabled")

    def __lt__(self: Ciphertensor[ctype], other) -> Ciphertensor[ctype]:
        raise NotImplementedError("Ciphertensors cannot be compared without IR pass enabled")

    def __eq__(self, other: Ciphertensor[ctype]) -> bool:
        if self.shape != other.shape or self.slots != other.slots: return False
        return self._data == other._data
    
    def aggregate(self, mpc) -> Ciphertensor[ctype]:
        if mpc.pid == 0:
            return self
        ct = mpc.comms.collect(self).sum(mpc)
        # ct._is_broadcast = True
        return ct
    
    def getitemdup(self, mpc, i: int, new_size: int) -> Ciphertensor[ctype]:
        assert self.ndim == 1, "Ciphertensor: getitemdup can be only from one-dimensional Ciphertensor"
        _data = []
        
        target_cipher_idx = i // self.slots
        target_offset = i % self.slots
        mask = mpc.mhe.enc_vector(one_hot_vector(target_offset, self.slots, TP=float), T=Plaintext)
        dedup_single = mpc.mhe.mul([self._data[target_cipher_idx]], mask)[0]

        ciphers_count = (new_size + self.slots - 1) // self.slots
        if ciphers_count > 1:
            dedup_base = dedup_single.copy()
            mpc.mhe.crypto_params.evaluator.reduce_add(dedup_base, self.slots)
        
            for _ in range(ciphers_count - 1):
                _data.append(dedup_base.copy())

        new_size_offset = new_size % self.slots
        if new_size_offset:
            dedup_edge = dedup_single.copy()
            distance = target_offset - new_size_offset + 1
            initial_rotation = distance if distance > 0 else (self.slots + distance)
            mpc.mhe.irotate([dedup_edge], initial_rotation)
            mpc.mhe.crypto_params.evaluator.reduce_add(dedup_edge, new_size_offset)
            _data.append(dedup_edge)
        elif len(_data):
            _data.append(_data[-1].copy())
        elif new_size:
            dedup_base = dedup_single.copy()
            mpc.mhe.crypto_params.evaluator.reduce_add(dedup_base, self.slots)
            _data.append(dedup_base)
        
        return Ciphertensor[ctype](
            _data=_data,
            shape=[new_size],
            slots=self.slots)
    
    def diagonal(self, idx: int) -> Ciphertensor[ctype]:
        diag_count = min(self.shape)
        idx %= diag_count
        
        if not self._diagonal_contiguous:
            raise NotImplementedError("Ciphertensor: getting diagonal of non-diagonal contiguous ciphertensor is not implemented yet")

        return self._get_rows_raw(idx)
    
    def mask(self, mpc, i: int) -> Ciphertensor[ctype]:
        assert self.ndim == 1, "Ciphertensor: only one-dimensional Ciphertensors can be masked"
        return self.mul(mpc, array(one_hot_vector(i, self.shape[0], TP=float)))

    @staticmethod
    def _count(shape):
        if len(shape) == 0:
            return 0
        total = 1
        for i in range(len(shape)):
            total *= shape[i]
        return total

    @staticmethod
    def _count_ciphers(shape, slots):
        if len(shape) == 0:
            return 0
        total = 1
        for i in range(len(shape) - 1):
            total *= shape[i]
        return (shape[-1] + slots - 1) // slots * total
    
    @staticmethod
    def enc(mpc, data, padding: int = 0, encoding: str = "") -> Ciphertensor[ctype]:
        if not encoding:
            encoding = mpc.default_ciphertensor_encoding
        
        if not encoding:
            encoding = ENC_ROW if data.shape[0] <= data.shape[-1] else ENC_COL
        
        if isinstance(data, ndarray):
            _data = data
        elif isinstance(data, list):
            _data = array(data)
        else:
            compile_error("Ciphertensor: invalid input for ciphertensor encoding/encryption")
        
        if _data.is_empty():
            return Ciphertensor[ctype](slots=mpc.mhe.crypto_params.params.slots())
        
        if not isinstance(_data.S, Tuple[int, int]):
            assert encoding == ENC_ROW, "Ciphertensor: 1-dimensional tensors can be encoded only row-wise"
            return Ciphertensor[ctype].enc_row_wise(mpc, _data, padding)
        
        if encoding == ENC_ROW:
            return Ciphertensor[ctype].enc_row_wise(mpc, _data, padding)
        elif encoding == ENC_COL:
            ctensor = Ciphertensor[ctype].enc_row_wise(mpc, _data.T, padding)
            ctensor._transposed = True
            return ctensor
        elif encoding == ENC_DIAG:
            return Ciphertensor[ctype].enc_diag_wise(mpc, _data, padding)
        else:
            raise ValueError("Invalid encoding")
    
    @staticmethod
    def enc_row_wise[S, dtype](mpc, data: ndarray[S, dtype], padding: int = 0) -> Ciphertensor[ctype]:
        if data.is_empty():
            return Ciphertensor[ctype](slots=mpc.mhe.crypto_params.params.slots())
        
        if padding:
            data = data.pad(padding, axis=(staticlen(S) - 1))
        
        slots = mpc.mhe.crypto_params.params.slots()
        vec_len = data.shape[-1]
        flat_data = data.flatten()
        _data = List[ctype](Ciphertensor._count_ciphers(data.shape, slots))
        
        for i in range(0, flat_data.size, vec_len):
            _data.extend(mpc.mhe.enc_vector(flat_data[i:i + vec_len].tolist(), T=ctype))

        return Ciphertensor[ctype](
            _data=_data,
            shape=list(data.shape),
            slots=slots)
    
    @staticmethod
    def enc_diag_wise[S, dtype](mpc, data: ndarray[S, dtype], padding: int = 0) -> Ciphertensor[ctype]:
        assert isinstance(S, Tuple[int, int]), "Ciphertensor: only 2-dimensional matrices can be diagonal-conting encoded"
        
        if data.is_empty():
            return Ciphertensor[ctype](
                slots=mpc.mhe.crypto_params.params.slots(),
                _diagonal_contiguous=True)
        
        diagonals = zeros((min(data.shape), max(data.shape)), dtype=dtype)
        
        for i in range(min(data.shape)):
            diagonals[i] = data.cyclic_diag(i)
        
        diag_contig_ctensor = Ciphertensor[ctype].enc_row_wise(mpc, diagonals, padding)
        diag_contig_ctensor._diagonal_contiguous = True
        diag_contig_ctensor._skinny = data.shape[1] < data.shape[0]
        return diag_contig_ctensor
    
    @staticmethod
    def enc_patch_copy(mpc, value, shape: list[int]) -> Ciphertensor[ctype]:
        if not (isinstance(value, int) or isinstance(value, float)):
            compile_error("Ciphertensor: invalid value type to patch_copy")
        
        slots = mpc.mhe.crypto_params.params.slots()
        enc_row = mpc.mhe.enc_vector([value for _ in range(shape[-1])], T=ctype)
        new_tensor_data = []
        for _ in range(shape[:-1].reduce_mul()):
            new_tensor_data.extend(enc_row.copy())
        
        return Ciphertensor[ctype](
            _data=new_tensor_data,
            shape=shape,
            slots=slots)
    
    @staticmethod
    def enc_alpern(mpc, data) -> List[List[Ciphertensor[ctype]]]:
        assert data.ndim == 3, "Ciphertensor: can enc only 3-dimensional arrays in Alpern order"
        m, n, p = data.shape
        alpern_shape = (n, p, m)
        alpern_data = data.reshape(alpern_shape)
        
        encryption = []
        for i in range(n):
            row = []
            for j in range(p):
                row.append(Ciphertensor[ctype].enc(mpc, alpern_data[i][j]))
            encryption.append(row)
        
        return encryption

    @staticmethod
    def zeros(mpc, shape: List[int]) -> Ciphertensor[Ciphertext]:
        slots = mpc.mhe.crypto_params.params.slots()
        number_of_elements = Ciphertensor._count_ciphers(shape, slots)
        zero_cipher = mpc.mhe.zero_cipher()
        
        return Ciphertensor[Ciphertext](
            _data=[zero_cipher.copy() for _ in range(number_of_elements)],
            shape=shape.copy(),
            slots=slots)
    
    @staticmethod
    def placeholder(shape: List[int], slots: int) -> Ciphertensor[ctype]:
        return Ciphertensor[Ciphertext](
            _data=[ctype.nil_ideal() for _ in range(Ciphertensor._count_ciphers(shape, slots))],
            shape=shape.copy(),
            slots=slots)
    
    @staticmethod
    def like[ctype](other: Ciphertensor) -> Ciphertensor[ctype]:
        return Ciphertensor[ctype](
            _data=[],
            shape=[],
            slots=other.slots,
            _transposed=other._transposed,
            _diagonal_contiguous=other._diagonal_contiguous,
            _skinny=other._skinny,
            _is_broadcast=other._is_broadcast)
    
    def zeros(self, mpc) -> Ciphertensor[Ciphertext]:
        return Ciphertensor[Ciphertext].zeros(mpc, self.shape)
    
    def set(self, other: Ciphertensor[ctype]):
        self._data = other._data
        self.shape = other.shape
        self.slots = other.slots
        self._chunk_size = other._chunk_size
        self._transposed = other._transposed
        self._diagonal_contiguous = other._diagonal_contiguous
        self._skinny = other._skinny

    def level(self) -> int:
        if not DEBUG:
            assert len(self._data), "Ciphertensor: cannot get level of an empty tensor"
        
        if len(self._data):
            return self._data[0].level()
        
        return 1024  # Until mpc instance is added to self. Then return mpc.mhe.crypto_params.params.max_level().
    
    def decrypt(self, mpc, source_pid: int = -2) -> Ciphertensor[Plaintext]:
        """
        If source_pid is:
            - PID number (0, 1, 2, ...), then only the ciphers at that PID will be decrypted and broadcast to all parties
            - -2, then each ciphervector will be collectively decrypted at each party one after the other
            - -1, then the ciphers are expected to be already shared (the same) between the parties
        """
        assert isinstance(ctype, Ciphertext), "Ciphertensor: data already decrypted"
        return Ciphertensor[Plaintext](
            _data=mpc.mhe.decrypt(self._data, source_pid),
            shape=self.shape.copy(),
            slots=self.slots,
            _transposed=self._transposed,
            _diagonal_contiguous=self._diagonal_contiguous,
            _skinny=self._skinny)
    
    def decode[T](self, mpc) -> ndarray[Tuple[int, int], T]:
        assert isinstance(ctype, Plaintext), "Ciphertensor: make sure to decrypt the ciphertensor before decoding it"
        assert 0 <= self.ndim < 3, "Ciphertensor: only 0-dim, 1-dim and 2-dim ciphertensors can be revealed at the moment"

        decoded_vector = mpc.mhe.decode(self._data, dtype=T)
        assert (decoded_vector.size() + self.slots - 1) // self.slots == len(self._data) == (self.cipher_shape.reduce_mul() if self.cipher_shape else 0), f"Ciphertensor: Input data shapes do not match encryption/encoding shape. Input shape: {decoded_vector.shape}. Enc vector len: {len(self._data)}. Slots: {self.slots}. Cipher shape: {self.cipher_shape}"
        
        # TODO: Remove the shapes adjustments after Ciphertensor is reimplemented to have a static shape
        if decoded_vector.size() == 0:
            return zeros(Tuple[int, int](0, 0), dtype=T)
        
        new_shape = self.cipher_shape
        new_shape[-1] *= self.slots
        new_shape_tuple = (new_shape[0], new_shape[1]) if self.ndim == 2 else (1, new_shape[0])
        shape_tuple = (self.shape[0], self.shape[1]) if self.ndim == 2 else (1, self.shape[0])

        arr = array(decoded_vector, dtype=T).reshape(new_shape_tuple).resize(shape_tuple)
        
        if self._diagonal_contiguous and self._skinny:
            arr = arr.diagonal_transpose(True).diagonal_contig(antidiagonal=True).T
        elif self._diagonal_contiguous:
            arr = arr.diagonal_contig(antidiagonal=True)
        
        return arr.T if self._transposed else arr
    
    def reveal[T=float](self, mpc, source_pid: int = -2) -> ndarray[Tuple[int, int], T]:
        if not bool(self):
            return ndarray[Tuple[int, int], T]()
        
        plain = self.decrypt(mpc, source_pid) if isinstance(ctype, Ciphertext) else self
        return plain.decode(mpc, T=T)
    
    def filter(self, mask) -> Ciphertensor[ctype]:
        assert self.ndim > 1, "Ciphertensor: cannot filter 1-dimensional ciphertensor"
        assert self.shape[0] == len(mask), "Ciphertensor: data and filter size mismatch"
        assert not self._transposed, "Not implemented yet: filtering transposed ciphertensor"
        
        new_data = []
        new_shape = self.shape.copy()
        new_shape[0] = 0
        for i, row in enumerate(self):
            if mask[i]:
                new_data.extend(row._data)
                new_shape[0] += 1
        
        return Ciphertensor[ctype](
            _data=new_data,
            shape=new_shape,
            slots=self.slots)
    
    def append(self, other: Ciphertensor[ctype]):
        assert not self._diagonal_contiguous and not other._diagonal_contiguous, "Ciphertensor: appending diagonal-contiguous ciphertensors is not implemented yet"
        assert not self._transposed and not other._transposed, "Ciphertensor: appending transposed ciphertensors is not implemented yet"
        assert self.ndim > 1, "Ciphertensor: cannot append to one-dimensional Ciphertensor"
        assert self.shape[1:] == other.shape, f"Ciphertensor: invalid shapes for append. Cannot append shape {other.shape} to shape {self.shape}"
        self._data.extend(other._data)
        self.shape[0] += 1
    
    def pop(self):
        assert not self._diagonal_contiguous, "Ciphertensor: popping diagonal-contiguous ciphertensors is not implemented yet"
        assert not self._transposed, "Ciphertensor: popping transposed ciphertensor is not implemented yet"
        assert self.ndim > 1, "Ciphertensor: cannot pop from one-dimensional Ciphertensor"
        self._data.len -= self._chunk_size
        self.shape[0] -= 1

    def pad_with_value(self, val, size: int, axis: int, mpc):
        assert -1 < axis < 2, "Ciphertensor: pad_with_value axis does not match the dimension"

        if axis == 0:
            appendix = Ciphertensor[ctype].enc(mpc, zeros((size, self.shape[1])) + val)
        # axis == 1
        appendix = Ciphertensor[ctype].enc(mpc, zeros((self.shape[0], size)) + val)
        
        return self.concat(mpc, appendix, axis)
    
    def extend(self, mpc, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        assert not (self._diagonal_contiguous ^ other._diagonal_contiguous), "Not implemented yet: extending diagonal-contiguous by non-diagonal-contiguous ciphertensors is not implemented yet"
        assert not (self._transposed ^ other._transposed), "Not implemented yet: extending transposed by non-transposed ciphertensor is not implemented yet"
        
        self_actual_shape = self.actual_shape
        other_actual_shape = other.actual_shape

        if self.ndim == 1:
            self.iconcat(mpc, other, axis=0)
            return self
        
        if self._diagonal_contiguous:
            assert self_actual_shape[0] == other_actual_shape[0], "Ciphertensor: shapes missmatch on extending diagonal-contiguous matrices"
            if self._transposed:
                assert not self._skinny, "Not implemented yet: extending fat diagonal-contiguous matrix is not implemented yet"
            else:
                assert self._skinny or self_actual_shape[0] == self_actual_shape[1], "Not implemented yet: extending fat diagonal-contiguous matrix is not implemented yet"

            self._iconcat_axis_1_raw(mpc, other)
            self.shape[1] += other.shape[1]
        else:
            assert self_actual_shape[1:] == other_actual_shape[1:], "Ciphertensor: invalid shapes for extend"
            if self._transposed:
                self._iconcat_axis_1_raw(mpc, other)
                self.shape[1] += other.shape[1]
            else:
                self._data.extend(other._data)
                self.shape[0] += other.shape[0]
        
        return self
    
    def iconcat(self, mpc, other: Ciphertensor[ctype], axis: int) -> Ciphertensor[ctype]:
        assert not self._diagonal_contiguous and not other._diagonal_contiguous, "Not implemented yet: concatenating non-diagonal-contiguous ciphertensors is not implemented yet"
        assert not (self._transposed ^ other._transposed), "Not implemented yet: concatenating transposed by non-transposed ciphertensor is not implemented yet"
        assert axis < self.ndim, "Ciphertensor: axis larger than ciphertensor dimension"
        assert self.ndim == other.ndim, "Ciphertensor: incompatible dimensions for concatenation"
        assert self.slots == other.slots, "Ciphertensor: incompatible slots for concatenation"
        
        if self.ndim == 1:
            self._data = Ciphertensor._concat_1_dim_raw(mpc, self, other)._data
        else:
            if self._transposed:
                axis ^= 1
            
            assert self.shape[axis ^ 1] == other.shape[axis ^ 1], "Ciphertensor: incompatible shapes for concatenation along provided axis"
            
            if axis == 0:
                self._data.extend(other._data)
            else:
                self._iconcat_axis_1_raw(mpc, other)
        
        self.shape[axis] += other.shape[axis]
        return self
    
    def concat(self, mpc, other: Ciphertensor[ctype], axis: int) -> Ciphertensor[ctype]:
        return self.copy().iconcat(mpc, other, axis)
    
    def resize(self, mpc, shape: list[int]) -> Ciphertensor[ctype]:
        assert self.ndim == 1 and len(shape) == 1, "Not implemented yet: Can resize only 1-dim to 1-dim ciphertensors"
        
        other_cipher_shape = (shape[-1] + self.slots - 1) // self.slots
        if self.shape == shape or (self.shape[-1] < shape[-1] and self.cipher_shape[-1] == other_cipher_shape):
            return Ciphertensor[ctype](
                _data=self._data.copy(),
                shape=shape.copy(),
                slots=self.slots)
        elif self.shape[-1] < shape[-1]:
            return self.concat(mpc, Ciphertensor[ctype].zeros(mpc, [shape[-1] - self.shape[-1]]), axis=0)
        else:
            mask = Ciphertensor[Plaintext].enc(mpc, [(1.0 if i < shape[-1] else 0.0) for i in range(self.shape[-1])])
            resized = self.mul(mpc, mask)

            return Ciphertensor[ctype](
                _data=resized._data[:other_cipher_shape],
                shape=shape.copy(),
                slots=self.slots)
    
    def expand_dims(self, axis=0) -> Ciphertensor[ctype]:
        assert not self._diagonal_contiguous, "Not implemented yet: expanding transposed or diag-contig ciphertensor"
        
        if self._transposed:
            axis ^= 1

        new_ctensor = self.copy()
        new_ctensor.shape.insert(axis, 1)
        new_ctensor._reset_chunk_size()
        
        return new_ctensor

    def ineg(self, mpc) -> Ciphertensor[Ciphertext]:
        if mpc.pid == 0: return self
        assert not isinstance(ctype, Plaintext), "Ciphertensor: cannot neg plaintext inplace"

        mpc.mhe.ineg(self._data)
        return self
    
    def iadd(self, mpc, other) -> Ciphertensor[Ciphertext]:
        if mpc.pid == 0: return self

        if isinstance(other, ByVal) and self.shape[-1] % self.slots == 0:
            mpc.mhe.iadd_const(self._data, other)
            return self

        assert not isinstance(ctype, Plaintext), "Ciphertensor: cannot add to plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)

        mpc.mhe.iadd(self._data, other_cipher._data)
        return self

    def isub(self, mpc, other) -> Ciphertensor[Ciphertext]:
        if mpc.pid == 0: return self

        if isinstance(other, ByVal) and self.shape[-1] % self.slots == 0:
            mpc.mhe.isub_const(self._data, other)
            return self

        assert not isinstance(ctype, Plaintext), "Ciphertensor: cannot subtract from plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)

        mpc.mhe.isub(self._data, other_cipher._data)
        return self

    def imul(self, mpc, other, no_refresh: bool = False) -> Ciphertensor[Ciphertext]:
        if mpc.pid == 0: return self

        if isinstance(other, ByVal):
            mpc.mhe.imul_const(self._data, other)
            return self

        assert not isinstance(ctype, Plaintext), "Ciphertensor: cannot multiply plaintext inplace"
        other_cipher = self._check_other_operand_elem_wise(mpc, other)

        mpc.mhe.imul(self._data, other_cipher._data, self._is_broadcast, other_cipher._is_broadcast, no_refresh)
        return self
    
    def ipow(self, mpc, p: int) -> Ciphertensor[Ciphertext]:
        if mpc.pid == 0: return self
        assert p > 0, f"Ciphertensor: invalid power {p} - should be larger than 0"
        assert not isinstance(ctype, Plaintext), "Ciphertensor: cannot pow plaintext inplace"

        butterfly_data = self._data.copy()
        tzs = p.__cttz__()

        for _ in range(tzs):
            mpc.mhe.imul(butterfly_data, butterfly_data)
        p >>= (tzs + 1)
        self._data = butterfly_data.copy()

        while p:
            mpc.mhe.imul(butterfly_data, butterfly_data)
            if p % 2:
                mpc.mhe.imul(self._data, butterfly_data)
            p >>= 1

        return self
    
    def irotate(self, mpc, step: int) -> Ciphertensor[ctype]:
        if mpc.pid == 0: return self
        shape = self.actual_shape
        step = (shape[-1] + step) % shape[-1]

        if step == 0:
            return self

        # Diagonal-contiguous rotation is cheaper than rotating the c-continguous matrix
        if self._diagonal_contiguous:
            assert self.ndim == 2, "Ciphertensor: cannot rotate --- diagonal-contiguous ciphertensor needs to be 2-dimensional"
            _data = []
            for i in range(self.shape[0]):
                _data.extend(self[(step + i) % self.shape[0]].irotate(mpc, step + i)._data)

            self._data = _data
        # Case c-contiguous 2-dimensional or higher tensor. Rotate only largest axis.
        elif self.ndim > 1:
            if self._transposed:
                self._irotate_raw(step)
            else:
                for row in self:
                    row.irotate(mpc, step)
        # Best case scenario. Rotating by multiplicative of slots requires no homomorphic rotation.
        elif step % self.slots == 0 and self.shape[-1] % self.slots == 0:
            self._data.irotate(step // self.slots)
        # Second-best case scenario. If cipher fits in the number of slots, only one homomorphic rotation is needed.
        elif self.shape[-1] == self.slots:
            mpc.mhe.irotate(self._data, step % self.slots)
        # Worst case scenario. Either the rotation is done over multiple ciphertexts or encoded data size is less than the number of slots
        else:
            # TODO: Check why this is buggy. Reproduce by using irotate in reduce_add_tiled diagonal encoding case.
            step_offset = step % self.slots % self.shape[-1]
            mpc.mhe.irotate(self._data, step_offset)

            mask = [(0 if (i < self.slots - step_offset) else 1) for i in range(self.slots)]
            cipher_mask = mpc.mhe.enc_vector(mask, T=Plaintext)[0]
            cipher_mask_inv = mpc.mhe.enc_vector(mask ^ 1, T=Plaintext)[0]
            mask_enc = [cipher_mask for _ in range(len(self._data))]
            mask_inv_enc = [cipher_mask_inv for _ in range(len(self._data))]
            
            offset_tensor_data = mpc.mhe.mul(self._data, mask_enc).irotate(1)
            
            data_offset = self.shape[-1] % self.slots
            if data_offset:
                mpc.mhe.irotate([offset_tensor_data[-1]], self.slots - data_offset)
            
            if data_offset and data_offset < step_offset:
                corr_mask = [(0 if (i < self.slots - step_offset + data_offset) else 1) for i in range(self.slots)]
                corr_cipher_mask = mpc.mhe.enc_vector(corr_mask, T=Plaintext)
                corr_cipher_mask_inv = mpc.mhe.enc_vector(corr_mask ^ 1, T=Plaintext)
                correction_cipher = mpc.mhe.mul([offset_tensor_data[-1]], corr_cipher_mask)
                mpc.mhe.imul([offset_tensor_data[-1]], corr_cipher_mask_inv)
                mpc.mhe.iadd([offset_tensor_data[-2]], correction_cipher)

            mpc.mhe.imul(self._data, mask_inv_enc)
            mpc.mhe.iadd(self._data, offset_tensor_data)

            if self.slots < step < self.shape[-1]:
                self._data.irotate((step + self.slots - 1) // self.slots)

        return self

    def neg(self, mpc):
        if isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, operator.neg)
        
        return self.copy().ineg(mpc)

    def add(self, mpc, other):
        if isinstance(ctype, Plaintext) and isinstance(other, Ciphertensor[Ciphertext]):
            return other.add(mpc, self)
        elif isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.add)
        
        return self.copy().iadd(mpc, other)

    def sub(self, mpc, other):
        assert not (isinstance(ctype, Plaintext) and isinstance(other, Ciphertensor[Ciphertext])), "Not implemented yet: cannot subtract ciphertext from plaintext"
        if isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.sub)
        
        return self.copy().isub(mpc, other)
    
    def mul(self, mpc, other):
        if isinstance(ctype, Plaintext) and isinstance(other, Ciphertensor[Ciphertext]):
            return other.mul(mpc, self)
        elif isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, other, operator.mul)
        
        return self.copy().imul(mpc, other)
    
    def pow(self, mpc, p):
        if isinstance(ctype, Plaintext):
            return self._handle_plaintext_case(mpc, p, operator.pow)
        
        return self.copy().ipow(mpc, p)

    def rotate(self, mpc, step: int) -> Ciphertensor[ctype]:
        return self.copy().irotate(mpc, step)

    def shift(self, mpc, step: int) -> Ciphertensor[ctype]:
        """
        Note: Shifting adds an extra ciphertext to the tensor and starts with (self.slots - step) number of zeros.
        Warning: This changes the shape of the ciphertensor. All zeros will be included in the rotated Ciphertensor.
        Example: [] - Ciphertensor, () - Single ciphertext
            [(1, 2, 3, 4), (5, 6, 7, 8)].shift(2) -> [(0, 0, 1, 2), (3, 4, 5, 6), (7, 8, 0, 0)]
        """
        assert mpc.pid, "Not implemented yet: shift at CP0"
        assert step < self.slots, "Ciphertensor: shifting requires step to be less than the number of slots per each cipher"
        assert self.ndim == 1, "Ciphertensor: only one-dimensional Ciphertensors can be shifted"

        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=float).shift_like_cipher(step, self.slots, self.shape[0]))

        shape = self.shape.copy()
        shape[-1] = (self.cipher_shape[-1] + 1) * self.slots

        return Ciphertensor[ctype](
            _data=mpc.mhe.shift(self._data, step),
            shape=shape,
            slots=self.slots,
            _transposed=self._transposed)

    def patch_copy(self, mpc, new_size: int, allow_transposed: bool = False):
        """
        Examples: [] - Ciphertensor, () - Single ciphertext
            [(1, 2, 3, 4), (5, 6, 0, 0)].patch_copy(7) -> [(1, 2, 3, 4), (5, 6, 1, 0)]
            [(1, 2, 3, 4), (5, 6, 0, 0)].patch_copy(8) -> [(1, 2, 3, 4), (5, 6, 1, 2)]
            [(1, 2, 3, 4), (5, 6, 0, 0)].patch_copy(9) -> [(1, 2, 3, 4), (5, 6, 1, 2), (3, 0, 0, 0)]
            [(1, 2, 3, 4), (5, 6, 0, 0)].patch_copy(10) -> [(1, 2, 3, 4), (5, 6, 1, 2), (3, 4, 0, 0)]
        """
        assert mpc.pid, "Not implemented yet: patch_copy at CP0"
        assert 0 < self.ndim < 3, "Ciphertensor: patch-copying can be applied only to 1-dim and 2-dim tensors"
        assert (self.actual_shape[-1] if allow_transposed else self.shape[-1]) < new_size, "Ciphertensor: can only patch_copy to larger array. Use Ciphertensor.resize() for trimming"

        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=float).patch_copy(new_size))

        patch_copy_tensor = self.copy()

        if self._diagonal_contiguous:
            raise NotImplementedError()
        elif self.ndim == 2:
            patch_copy_data = []

            if self._transposed and allow_transposed:
                for i in range(new_size // self.shape[0]):
                    patch_copy_data.extend(patch_copy_tensor._data.copy())
                if new_size % self.shape[0]:
                    patch_copy_data.extend(patch_copy_tensor._get_rows_raw(slice(0, new_size % self.shape[0], 1))._data.copy())
            else:
                for i in range(self.shape[0]):
                    patch_copy_data.extend(patch_copy_tensor._get_rows_raw(i).patch_copy(mpc, new_size)._data)

            return Ciphertensor[ctype](
                _data=patch_copy_data,
                shape=[new_size, self.shape[1]] if self._transposed and allow_transposed else [self.shape[0], new_size],
                slots=self.slots,
                _transposed=self._transposed,
                _diagonal_contiguous=self._diagonal_contiguous)

        if self.shape[-1] == 1:
            patch_copy_tensor = patch_copy_tensor.pad(mpc, new_size)
            return patch_copy_tensor.reduce_add(mpc)
        
        while patch_copy_tensor.shape[0] < new_size:
            offset = patch_copy_tensor.shape[0] % self.slots
            if offset:
                shifted_tensor_data = patch_copy_tensor.shift(mpc, self.slots - offset)._data

                if patch_copy_tensor.shape[0] % self.slots <= self.slots - offset:
                    # Last cipher in shifted tensor is all zeros
                    shifted_tensor_data.pop()

                mpc.mhe.crypto_params.evaluator.add(
                    patch_copy_tensor._data[-1],
                    shifted_tensor_data[0],
                    patch_copy_tensor._data[-1])
                
                patch_copy_tensor._data.extend(shifted_tensor_data[1:])
            else:
                patch_copy_tensor._data.extend(patch_copy_tensor._data.copy())
            patch_copy_tensor.shape[0] <<= 1

        for _ in range(len(patch_copy_tensor._data) - (new_size + self.slots - 1) // self.slots):
            patch_copy_tensor._data.pop()

        offset = new_size % self.slots
        if offset and ((new_size >> (new_size.__cttz__())) != self.shape[0]):  # if offset or self.shape[0] != new_size // 2^k
            mask = mpc.mhe.enc_vector([(1.0 if i < offset else 0.0) for i in range(self.slots)], T=Plaintext)
            patch_copy_tensor._data[-1] = mpc.mhe.mul([patch_copy_tensor._data[-1]], mask)[0]

        patch_copy_tensor.shape = [new_size]

        return patch_copy_tensor
    
    def pad(self, mpc, new_size: int) -> Ciphertensor[ctype]:
        assert mpc.pid, "Not implemented yet: pad at CP0"
        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=float).pad(new_size))
        
        _data = self._data.copy()

        # TODO: There should be no need for masking here
        mask = mpc.mhe.enc_vector([(1.0 if i < self.shape[-1] % self.slots else 0.0) for i in range(self.slots)], T=Plaintext)
        mpc.mhe.imul([_data[-1]], mask)

        zero_cipher = mpc.mhe.zero_cipher()
        _padding = [zero_cipher.copy() for _ in range((new_size - 1) // self.slots)]
        _data.extend(_padding)
        
        return Ciphertensor[ctype](
            _data=_data,
            shape=[new_size],
            slots=self.slots)
    
    def reduce_add(self, mpc, keep_dims: bool = True) -> Ciphertensor[ctype]:
        assert mpc.pid, "Not implemented yet: reduce_add at CP0"
        assert self.ndim == 1, "Ciphertensor: addition reduction can be applied only to 1-dimensional tensors"
        
        size = self.shape[-1] if keep_dims else 1

        if isinstance(ctype, Plaintext):
            # TODO: Read dtype (T) from other (add dtype static to Ciphertensor class)
            _sum: float = self.decode(mpc, T=float).sum()
            cipher = Ciphertensor[Plaintext].enc(mpc, [_sum for _ in range(size)])
        else:
            cipher = Ciphertensor[ctype](
                _data=mpc.mhe.reduce_add(self._data, self.shape[-1], keep_dims=keep_dims),
                shape=[size],
                slots=self.slots)
        
        cipher._transposed = self._transposed
        return cipher

    def reduce_add_tiled(self, mpc, tile_size: int) -> Ciphertensor[ctype]:
        assert mpc.pid, "Not implemented yet: reduce_add_tiled at CP0"
        assert 0 < self.ndim < 3, "Ciphertensor: tiled addition reduction can be applied only to 1-dim and 2-dim tensors"

        if self.ndim == 2:
            assert not self._transposed, "Not implemented yet: tiled addition reduction of transposed matrices"
            if self._diagonal_contiguous:
                assert not self._skinny, "Not implemented yet: tiled addition reduction of skinny diagonal-contiguous matrices"
                actual_tile_size = tile_size
                tile_size = max(self.shape[0], tile_size)

            reduced_tiled_data = []
            for i in range(self.shape[0]):
                reduced_tiled_data.extend(self._get_rows_raw(i).reduce_add_tiled(mpc, tile_size)._data)
            
            ct = Ciphertensor[ctype](
                _data=reduced_tiled_data,
                shape=[self.shape[0], tile_size],
                slots=self.slots,
                _transposed=self._transposed,
                _diagonal_contiguous=self._diagonal_contiguous,
                _skinny=False)
            
            if not self._diagonal_contiguous or actual_tile_size >= self.shape[0]:
                return ct
            
            assert tile_size <= self.slots >> 1, "Not implemented yet: reduce add of large skinny matrix"
            ct._diagonal_contiguous = False
            patched_ct = ct.patch_copy(mpc, tile_size << 1)
            mpc.mhe.irotate(patched_ct._data, tile_size)
            patched_ct._diagonal_contiguous = True
            diagonals = [patched_ct.diagonal(i) for i in range(tile_size)]
            
            while actual_tile_size < tile_size:
                tile_size >>= 1
                for i in range(tile_size):
                    mpc.mhe.irotate(diagonals[i + tile_size]._data, -tile_size)
                    diagonals[i].iadd(mpc, diagonals[i + tile_size])

            mask = mpc.mhe.enc_vector([(1.0 if i < self.shape[0] else 0.0) for i in range(self.slots)], T=Plaintext)
            new_data = []
            for i in range(tile_size):
                mpc.mhe.imul(diagonals[i]._data, mask)
                new_data.extend(diagonals[i]._data)
            
            return Ciphertensor[ctype](
                _data=new_data,
                shape=[tile_size, self.shape[0]],
                slots=self.slots,
                _transposed=self._transposed,
                _diagonal_contiguous=self._diagonal_contiguous,
                _skinny=True)
        
        if tile_size == 1:
            return self.reduce_add(mpc, keep_dims=False)
        
        size = self.shape[0]
        cipher_offset = size % self.slots
        tile_offset = self.slots % tile_size
        if tile_size > self.slots // 2 or ((cipher_offset or tile_offset) and len(self._data) > 1):
            raise NotImplementedError(
                f"CP{mpc.pid}: Ciphertensor: tiled addition reduction case not implemented yet:\n"
                f"\tCipher size: {size}\n"
                f"\tTile size: {tile_size}\n"
                f"\tTile size greater than slots: {tile_size > self.slots}\n"
                f"\tTile offset: {tile_offset}\n"
                f"\tCipher offset: {cipher_offset}")
        
        cipher = self._data[0].copy()
        
        for i in range(1, len(self._data)):
            mpc.mhe.crypto_params.evaluator.add(cipher, self._data[i], cipher)

        rotation_step = tile_size
        while rotation_step < size:
            rotated_cipher = mpc.mhe.rotate([cipher], rotation_step)[0]
            if rotation_step > self.slots // 2:
                mask = mpc.mhe.enc_vector([(1.0 if i < (self.slots - rotation_step) else 0.0) for i in range(self.slots)], T=Plaintext)
                mpc.mhe.imul([rotated_cipher], mask)
            mpc.mhe.crypto_params.evaluator.add(cipher, rotated_cipher, cipher)
            rotation_step <<= 1
        
        mask = mpc.mhe.enc_vector([(1.0 if i < tile_size else 0.0) for i in range(self.slots)], T=Plaintext)
        return Ciphertensor[ctype](
            _data=mpc.mhe.mul([cipher], mask),
            shape=[tile_size],
            slots=self.slots)
    
    def sum(self, mpc, axis: int) -> Ciphertensor[ctype]:
        assert mpc.pid, "Not implemented yet: sum at CP0"
        assert 0 < self.ndim < 3, "Ciphertensor: can sum only for 1-dimensional and 2-dimensional ciphertensors"
        assert 0 <= axis < self.ndim, "Ciphertensor: axis not present within the dimensions of the ciphertensor"
        
        if self.ndim == 1:
            _sum = self.reduce_add(mpc, keep_dims=False)
            _sum.shape = [1]
            return _sum
        
        if self._transposed:
            axis ^= 1
        
        if axis == 0:
            _sum = self._get_rows_raw(0).copy()
            for i in range(1, self.shape[0]):
                _sum.iadd(mpc, self._get_rows_raw(i))
            
            if self._diagonal_contiguous and self._skinny:
                _sum = _sum.reduce_add_tiled(mpc, min(self.shape))

            return _sum
        
        if axis == 1:
            assert not self._diagonal_contiguous, "Not implemented yet: Sum of diagonal-contiguous ciphertensor over axis 1"
            assert self.shape[0] < self.slots, "Not implemented yet: ciphertensor sum over axis 1: case number of rows greater than the number of slots"
            
            _sum_data = self._get_rows_raw(0).sum(mpc, axis=0)._data
            for i in range(1, self.shape[0]):
                mpc.mhe.iadd(
                    _sum_data,
                    mpc.mhe.irotate(
                        self._get_rows_raw(i).sum(mpc, axis=0)._data,
                        self.slots - i))
            
            return Ciphertensor[ctype](
                _data=_sum_data,
                shape=[self.shape[0]],
                slots=self.slots)
            
        raise ValueError("invalid axis for ciphertensor.sum")
    
    def dot(self, mpc, other: Ciphertensor, axis: int) -> Ciphertensor[ctype]:
        if mpc.pid == 0:
            new_shape = self.shape.copy()
            new_shape[-1] = 1
            return Ciphertensor[ctype].zeros(mpc, new_shape)

        assert 0 <= axis < self.ndim, "Ciphertensor: axis not present within the dimensions of the ciphertensor"
        return self.mul(mpc, other).sum(mpc, axis=axis)
    
    def dot(self, mpc, axis: int) -> Ciphertensor[ctype]:
        return self.dot(mpc, self, axis)
    
    def matmul(self, mpc, other, debug: Static[int] = DEBUG) -> Ciphertensor[ctype]:
        if mpc.pid == 0:
            self_shape = self.actual_shape
            other_shape = other.actual_shape
            new_shape = [self_shape[0], other_shape[1]]
            return Ciphertensor[ctype].zeros(mpc, new_shape)
        
        assert self.ndim == other.ndim == 2, f"Ciphertensor: at least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other.shape}. Ciphertensor matmul supports only matrices at the moment"
        
        if isinstance(other, Ciphertensor):
            if self._diagonal_contiguous or other._diagonal_contiguous:
                return self._matmul_v3(mpc, other, debug)
            elif self._transposed and other._transposed:
                return other.T._matmul_v2(mpc, self.T, debug).T
            elif self._transposed:
                return self._matmul_tnt(mpc, other, debug)
            elif other._transposed:
                return self._matmul_v1(mpc, other, debug)
            else:
                return self._matmul_v2(mpc, other, debug)
        elif isinstance(other, ndarray):
            return self._switch_matmul_by_cost(mpc, other, debug)
        elif isinstance(other, list):
            return self._switch_matmul_by_cost(mpc, array(other), debug)
        else:
            compile_error("Invalid matmul operand type")

    def iget_actual(self, mpc) -> Ciphertensor[ctype]:
        if self.ndim == 1:
            self._transposed = False
            self._diagonal_contiguous = False
            self._skinny = False
            return self
        
        if not self._transposed and not self._diagonal_contiguous:
            return self
        
        if isinstance(ctype, Plaintext):
            # TODO: Read dtype from self (add dtype static to Ciphertensor class)
            self.set(Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=float)))
            return self
        
        self.set(self.via_mpc(mpc, lambda stensor: stensor, S=Tuple[int, int]))
        return self
    
    def get_actual(self, mpc) -> Ciphertensor[ctype]:
        if self.ndim == 1:
            actual_ct = self.copy()
            actual_ct._transposed = False
            actual_ct._diagonal_contiguous = False
            actual_ct._skinny = False
            return actual_ct
        
        if not self._transposed and not self._diagonal_contiguous:
            return self.copy()
        
        if isinstance(ctype, Plaintext):
            # TODO: Read dtype from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=float))
    
        if self._diagonal_contiguous and self._transposed:
            return self.diagonal_transpose(mpc)
        
        return self.via_mpc(mpc, lambda stensor: stensor, S=Tuple[int, int])
    
    def actual_transpose(self, mpc) -> Ciphertensor[ctype]:
        if self.ndim < 2:
            return self
        
        if self._transposed:
            return self.T
        
        if isinstance(ctype, Plaintext):
            # TODO: Read dtype from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(
                mpc, self.decode(mpc, T=float).T,
                encoding=ENC_DIAG if self._diagonal_contiguous else ENC_ROW)
        
        if self._diagonal_contiguous:
            return self.diagonal_transpose(mpc)
        
        return self.via_mpc(mpc, lambda stensor: stensor.T, S=Tuple[int, int])

    def diagonal_transpose(self, mpc):
        assert self._diagonal_contiguous, "Ciphertensor: diagonal transpose should be called only on diagonal-encoded ciphertensors"

        if self._transposed:
            return self.T
        
        diag_count = min(self.shape)
        diagonals = [
            self.diagonal(i).rotate(mpc, -i + diag_count * int(not self._skinny))
            for i in range(1, diag_count)]
        diagonals.reverse()

        new_data = self.diagonal(0)._data.copy()
        for i in range(diag_count - 1):
            new_data.extend(diagonals[i]._data)

        return Ciphertensor[ctype](
            _data=new_data,
            shape=self.shape.copy(),
            slots=self.slots,
            _transposed=False,
            _diagonal_contiguous=True,
            _skinny=(self._skinny ^ True) and self.shape[0] != self.shape[1])
    
    def diagonal_contig(self, mpc) -> Ciphertensor[ctype]:
        if self.ndim < 2 or self._diagonal_contiguous:
            return self
        
        if isinstance(ctype, Plaintext):
            actual_plain = self.decode(mpc, T=float)
            # TODO: Read dtype from self (add dtype static to Ciphertensor class)
            return Ciphertensor[Plaintext].enc(mpc, actual_plain, encoding=ENC_DIAG)
        
        diag_ct = self.via_mpc(mpc, lambda stensor: stensor.diagonal_contig(), S=Tuple[int, int])
        diag_ct._diagonal_contiguous = True
        
        m, n = self.actual_shape
        diag_ct._skinny = n < m

        return diag_ct
    
    def via_mpc[S](self, mpc, foo, *args, mirrored=False, exclude_parties=Set[int]()):
        if mirrored:
            stensor = self.to_sharetensor(mpc, modulus=mpc.default_mpc_modulus, source_pid=-1, S=S, dtype=float)
            mpc_output = foo(stensor, *args)
            return mpc_output.to_ciphertensor(mpc) if mpc.pid else self
        
        ctensors = mpc.comms.collect(self, exclude_parties=exclude_parties)
        processed_ctensors = {}

        for i in range(mpc.comms.number_of_parties - 1):
            if i in exclude_parties or (mpc.pid and not ctensors[i]):
                continue
            
            ctensor = ctensors[i] if mpc.pid else self
            stensor = ctensor.to_sharetensor(mpc, modulus=mpc.default_mpc_modulus, source_pid=-1, S=S, dtype=float)
            stensor = foo(stensor, *args)
            processed_ctensors[i + 1] = stensor.to_ciphertensor(mpc)
        
        if mpc.pid == 0 or mpc.pid in exclude_parties:
            return self
        
        return processed_ctensors[mpc.pid]

    def get_matmul_cost(self, other) -> float:
        if isinstance(other, Ciphertensor):
            if self._diagonal_contiguous or other._diagonal_contiguous:
                return Ciphertensor._get_matmul_v3_cost(self, other)
            elif self._transposed and other._transposed:
                return Ciphertensor._get_matmul_v2_cost(other.T, self.T)
            elif self._transposed:
                return Ciphertensor._get_matmul_tnt_cost(self, other)
            elif other._transposed:
                return Ciphertensor._get_matmul_v1_cost(self, other)
            else:
                return Ciphertensor._get_matmul_v2_cost(self, other)
        elif isinstance(other, ndarray) or isinstance(other, list):
            return Ciphertensor._get_matmul_public_cost(self, other)
        else:
            compile_error("Invalid matmul operand type")
    
    def local_broadcast[S2](self, mpc, target_shape: S2) -> Ciphertensor[ctype]:
        if self.shape == list(target_shape):
            return self
        
        assert self.ndim == len(target_shape) == 1, f"Not implemented yet: broadcasting {self.ndim}-dimensional to {len(target_shape)}-dimensional Ciphertensor. Shapes: {self.shape} -> {target_shape}"
        return self.patch_copy(mpc, target_shape[0])

    def validate(self):
        assert len(self._data) == Ciphertensor._count_ciphers(self.shape, self.slots), "Ciphertensor: ciphertensor failed validation"

    @staticmethod
    def requires_collective[C1, C2](first: Ciphertensor[C1], other: Ciphertensor[C2]) -> bool:
        return first._transposed ^ other._transposed

    @staticmethod
    def _get_matmul_public_cost(first, other):
        if first._diagonal_contiguous:
            raise NotImplementedError()
        if first._transposed:
            return Ciphertensor._get_matmul_tnt_cost(first, other)
        
        return min(
            Ciphertensor._get_matmul_v1_cost(first, other),
            Ciphertensor._get_matmul_v2_cost(first, other),
            Ciphertensor._get_matmul_v3_cost(first, other))
    
    @staticmethod
    def _get_matmul_via_mpc_cost_by_shape(first_shape, other_shape, slots):
        ctx_per_row = (first_shape[1] + slots - 1) // slots
        mpc_switch_cost = first_shape[0] * ctx_per_row * MHE_MPC_SWITCH_COST_ESTIMATE
        iter_count = first_shape[0] * first_shape[1] * other_shape[1]
        
        return iter_count * MPC_BIG_INT_MUL_COST + mpc_switch_cost
    
    @staticmethod
    def _get_matmul_v1_cost_by_shape(first_shape, other_shape, slots):
        ctx_per_row = (first_shape[1] + slots - 1) // slots
        iter_count = first_shape[0] * other_shape[1]

        return iter_count * (ctx_per_row * HE_MUL_COST_ESTIMATE + (slots - 1).bitlen() * HE_ROT_COST_ESTIMATE)

    @staticmethod
    def _get_matmul_v2_cost_by_shape(first_shape, other_shape, slots):
        ctx_per_row = (other_shape[1] + slots - 1) // slots
        iter_count = first_shape[0] * first_shape[1]

        return (ctx_per_row * iter_count * HE_MUL_COST_ESTIMATE +
                iter_count * (HE_MUL_COST_ESTIMATE + (min(other_shape[1], slots) - 1).bitlen() * HE_ROT_COST_ESTIMATE))
    
    @staticmethod
    def _get_matmul_v3_cost_by_shape(first_shape, other_shape, slots):
        ctx_per_row = (max(max(first_shape), max(other_shape)) + slots - 1) // slots
        iter_count = first_shape[0] * min(other_shape)
        masking_overhead = 2 if ctx_per_row > 1 else 1

        return (ctx_per_row * iter_count * (HE_MUL_COST_ESTIMATE * masking_overhead + HE_ROT_COST_ESTIMATE) +
                (max(other_shape) - 1).bitlen() * HE_ROT_COST_ESTIMATE)
    
    @staticmethod
    def _get_matmul_tnt_cost_by_shape(first_shape, other_shape, slots):
        cost_per_cipher = (max(first_shape[0], max(other_shape)) + slots - 1) // slots
        iter_count = min(first_shape[0], other_shape[1]) * other_shape[0]

        return cost_per_cipher * iter_count * (HE_MUL_COST_ESTIMATE + HE_ROT_COST_ESTIMATE)
    
    @staticmethod
    def _get_matmul_via_mpc_cost(first, other):
        return Ciphertensor._get_matmul_via_mpc_cost_by_shape(first.shape, other.actual_shape, first.slots)
    
    @staticmethod
    def _get_matmul_v1_cost(first, other):
        return Ciphertensor._get_matmul_v1_cost_by_shape(first.shape, other.actual_shape, first.slots)

    @staticmethod
    def _get_matmul_v2_cost(first, other):
        return Ciphertensor._get_matmul_v2_cost_by_shape(first.shape, other.shape, first.slots)
    
    @staticmethod
    def _get_matmul_v3_cost(first, other):
        return Ciphertensor._get_matmul_v3_cost_by_shape(first.shape, other.shape, first.slots)
    
    @staticmethod
    def _get_matmul_tnt_cost(first, other):
        return Ciphertensor._get_matmul_tnt_cost_by_shape(first.actual_shape, other.shape, first.slots)

    def _irotate_raw(self, step: int):
        assert self.ndim > 1, "Ciphertensor: cannot irotate raw from one-dimensional ciphertensor"
        self._data.irotate(step * self._chunk_size)
    
    def _switch_matmul_by_cost[dtype](self, mpc, other: ndarray[Tuple[int, int], dtype], debug: Static[int]) -> Ciphertensor[ctype]:
        if isinstance(ctype, Plaintext):
            return Ciphertensor[Plaintext].enc(mpc, self.decode(mpc, T=dtype) @ other)
        
        if self._diagonal_contiguous:
            if debug:
                print(f"\nCP{mpc.pid}:\tMatmul costs estimation skipped for cyclic-diagonal case. Public operand is coerced into cyclic-diagonal encoding.\n")
            return self._matmul_v3(mpc, Ciphertensor[Plaintext].enc(mpc, other, encoding=ENC_DIAG), debug)
        if self._transposed:
            costs = (Ciphertensor._get_matmul_tnt_cost(self, other),
                     ndarray._get_matmul_v2_cost(other, self, transposed=True))
            
            if debug:
                print(f"\nCP{mpc.pid}:\tMatmul costs for transposed case:\n\tTNT: {costs[0]}\n\tM2: {costs[1]}\n")
            
            match argmin(costs):
                case 0:
                    return self._matmul_tnt(mpc, other, debug)
                case 1:
                    return other.T._matmul_v2(mpc, self.T, debug).T
                case _:
                    raise ValueError("Invalid cost index")
        
        costs = (Ciphertensor._get_matmul_via_mpc_cost(self, other),
                 Ciphertensor._get_matmul_v1_cost(self, other),
                 Ciphertensor._get_matmul_v2_cost(self, other),
                 Ciphertensor._get_matmul_v3_cost(self, other))
        
        m, n = other.shape
        if m % n and n % m:
            # TODO: temporary constraint: matmul dimensions need to divisible by each-other in v3 matmul for now"
            costs = (*costs[:-1], inf)
        
        if not mpc.default_allow_mpc_switch:
            costs = (inf, *costs[1:])
        
        if debug:
            print(f"\nCP{mpc.pid}:\tMatmul costs:\n\tVia SMC: {costs[0]}\n\tM1: {costs[1]}\n\tM2: {costs[2]}\n\tM3: {costs[3]}\n")
                
        match argmin(costs):
            case 0:
                return self.via_mpc(mpc, lambda stensor: secure_operator.matmul(mpc, stensor, other), S=Tuple[int, int])
            case 1:
                other_cipher = Ciphertensor[Plaintext].enc(mpc, other.T)
                other_cipher._transposed = True
                return self._matmul_v1(mpc, other_cipher, debug)
            case 2:
                return self._matmul_v2(mpc, Ciphertensor[Plaintext].enc(mpc, other, encoding=ENC_ROW), debug)
            case 3:
                return self._matmul_v3(mpc, Ciphertensor[Plaintext].enc(mpc, other, encoding=ENC_DIAG), debug)
            case _:
                raise ValueError("Invalid cost index")
    
    def _matmul_v1(self, mpc, other: Ciphertensor, debug: Static[int]):
        """
        M1 method from https://arxiv.org/pdf/2304.00129.pdf
        """
        self_shape = self.shape
        other_shape = other.shape
        if debug: print(f"CP{mpc.pid}:\tUsing M1 method for ciphertensor matrix multiplication for {self_shape} x {other_shape} operands")
        assert self_shape[1] == other_shape[1], f"Ciphertensor: invalid matrix dimentions for M1 matmul {self_shape} x {other_shape}"
        assert other._transposed, "Ciphertensor: ciphertensor should be lazily transposed prior to M1 matrix multiplication by it"
        assert not self._diagonal_contiguous and not other._diagonal_contiguous, "Ciphertensor: cannot apply M1 matrix multiplication method to diagonal-contiguous ciphertensors"

        masks = [mpc.mhe.enc_vector(one_hot_vector(i % self.slots, self.slots, TP=float), T=Plaintext) for i in range(other_shape[0])]
        
        new_ciphertensor = Ciphertensor[Ciphertext](
                shape=[0, other_shape[0]],
                slots=self.slots)
        for i in range(self_shape[0]):
            new_row = Ciphertensor[Ciphertext].zeros(mpc, [other_shape[0]])

            for j in range(other_shape[0]):
                reduction = self._get_rows_raw(i).mul(mpc, other._get_rows_raw(j)).reduce_add(mpc)

                if reduction.shape[0] < other_shape[0]:
                    reduction = reduction.patch_copy(mpc, other_shape[0])

                target_cipher = new_row._data[j // self.slots]
                mpc.mhe.crypto_params.evaluator.add(
                    target_cipher,
                    mpc.mhe.mul([reduction._data[0]], masks[j])[0],
                    target_cipher)
                if debug: print(f"CP{mpc.pid}:\tCiphertensor M1 matmul: {i + 1}/{self_shape[0]} -- {j + 1}/{other_shape[0]}")
            if debug: print(f"CP{mpc.pid}:\t----------------------")
            
            new_ciphertensor.append(new_row)
        
        return new_ciphertensor

    def _matmul_v2(self, mpc, other: Ciphertensor, debug: Static[int]):
        """
        M2 method from https://arxiv.org/pdf/2304.00129.pdf
        """
        self_shape = self.shape
        other_shape = other.shape
        if debug: print(f"CP{mpc.pid}:\tUsing M2 method for ciphertensor matrix multiplication for {self_shape} x {other_shape} operands")
        assert self_shape[1] == other_shape[0], f"Ciphertensor: invalid matrix dimentions for M2 matmul {self_shape} x {other_shape}"
        assert not self._transposed and not other._transposed, "Ciphertensor: ciphertensors should not be lazily transposed prior to M2 matrix multiplication"
        assert not self._diagonal_contiguous and not other._diagonal_contiguous, "Ciphertensor: cannot apply M1 matrix multiplication method to diagonal-contiguous ciphertensors"

        new_ciphertensor = Ciphertensor[ctype].zeros(mpc, [self_shape[0], other_shape[1]])

        mpc.mhe.refresh(self._data, self._is_broadcast, min_level_distance=1)
        if isinstance(other, Ciphertensor[Ciphertext]):
            mpc.mhe.refresh(other._data, other._is_broadcast)
        
        for i in range(self_shape[0]):
            if debug: print(f"CP{mpc.pid}:\tCiphertensor M2 matmul: {i + 1}/{self_shape[0]} ...")
            new_row = new_ciphertensor._get_rows_raw(i)
            self_row = self._get_rows_raw(i)
            for j in range(self_shape[1]):
                self_elem_duplicated = self_row.getitemdup(mpc, j, other_shape[1])
                new_row.iadd(mpc, other._get_rows_raw(j).mul(mpc, self_elem_duplicated))
        
        return new_ciphertensor

    def _matmul_v3(self, mpc, other: Ciphertensor, debug: Static[int]) -> Ciphertensor[ctype]:        
        m, n = other.shape
        assert m % n == 0 or n % m == 0, "Ciphertensor: temporary constraint --- matmul dimensions need to be divisible by eachother --- this is soon to be fixed"
        
        if self._diagonal_contiguous and other._diagonal_contiguous:
            return self._matmul_v3_11(mpc, other, debug)
        elif self._diagonal_contiguous:
            return self._matmul_v3_10(mpc, other, debug)
        elif other._diagonal_contiguous:
            return self._matmul_v3_01(mpc, other, debug)
        else:
            raise ValueError("Ciphertensor: cannot apply M3 matrix multiplication method if none of the operands is diagonal-contiguous")
    
    def _matmul_v3_01(self, mpc, other: Ciphertensor, debug: Static[int]):
        """
        M3 method from https://arxiv.org/pdf/2304.00129.pdf
        Case self non-diagonal-contiguous and other is diagonal-contiguous.
        """
        self_actual_shape = self.actual_shape
        other_actual_shape = other.actual_shape
        
        self_is_broadcast = self._is_broadcast
        other_is_broadcast = other._is_broadcast
        
        if debug: print(f"CP{mpc.pid}:\tUsing M3 method for ciphertensor matrix multiplication for {self_actual_shape} x {other_actual_shape} operands")
        assert self_actual_shape[1] == other_actual_shape[0], f"Ciphertensor: Invalid matrix dimensions for M3 matmul {self_actual_shape} x {other_actual_shape}"
        assert other._diagonal_contiguous, "Ciphertensor: _matmul_v3_01 expects second operand to be diagonal-contiguous"
        assert not self._transposed, "Not implemented yet: col-wise x diagonal-wise matmul case is not added yet"
        if other._transposed:
            other = other.T.actual_transpose(mpc)
        assert not other._transposed, "Ciphertensor: internal error"

        if self.shape[1] < other.shape[1]:
            mpc.mhe.refresh(self._data, self._is_broadcast, min_level_distance=2)
            patch_copy_self = self.patch_copy(mpc, other.shape[1])
        else: patch_copy_self = self.copy()

        semi_slot = patch_copy_self.shape[1] < self.slots >> 1
        # No need to do actual rotation downstream if data size is less than slots // 2
        # Patch copy self to double size
        if semi_slot:
            patch_copy_self = patch_copy_self.patch_copy(mpc, patch_copy_self.shape[1] << 1)
            # Assume diagonals are trailed by zeros and pad them lazily by expanding shape
            other.shape[1] <<= 1
        
        mpc.mhe.refresh(patch_copy_self._data, self._is_broadcast, min_level_distance=2)
        if isinstance(other, Ciphertensor[Ciphertext]):
            mpc.mhe.refresh(other._data, other._is_broadcast)
        
        new_data = []
        debug_counter = 0
        for row in patch_copy_self:
            if debug:
                debug_counter += 1
                print(f"CP{mpc.pid}:\tCiphertensor M3 matmul v01: {debug_counter}/{patch_copy_self.shape[0]} ...")
            
            new_row = row.mul(mpc, other.diagonal(0))
            
            row._is_broadcast = self_is_broadcast
            for i in range(1, min(other.shape)):
                rotated_row = row.copy()

                if semi_slot:
                    mpc.mhe.irotate(rotated_row._data, i)
                else:
                    rotated_row.irotate(mpc, i)
                
                other_diag = other.diagonal(i)
                other_diag._is_broadcast = other_is_broadcast
                rotated_row.imul(mpc, other_diag, no_refresh=True)
                new_row.iadd(mpc, rotated_row)
            
            new_data.extend(new_row._data)
        
        mpc.mhe.refresh(new_data)
        
        new_ciphertensor = Ciphertensor[ctype](
            _data=new_data,
            shape=patch_copy_self.shape,
            slots=self.slots)

        if semi_slot:
            other.shape[1] >>= 1
        
        if other_actual_shape[1] < patch_copy_self.shape[1]:
            return new_ciphertensor.reduce_add_tiled(mpc, other_actual_shape[1])
        elif semi_slot:
            new_ciphertensor.shape[1] >>= 1
            new_ciphertensor._reset_chunk_size()
        
        return new_ciphertensor

    def _matmul_v3_10(self, mpc, other: Ciphertensor, debug: Static[int]):
        raise NotImplementedError("INTERNAL: _matmul_v3_10 case not implemented yet")
        return Ciphertensor[ctype]()
    
    def _matmul_v3_11(self, mpc, other: Ciphertensor, debug: Static[int]):
        if self._transposed:
            self_nt = self.T.actual_transpose(mpc)
        else:
            self_nt = self
        
        if self_nt._skinny:
            return self_nt._matmul_v3_11_tall(mpc, other, debug)

        return self_nt._matmul_v3_11_wide(mpc, other, debug)
    
    def _matmul_v3_11_wide(self, mpc, other: Ciphertensor, debug: Static[int]):        
        assert not self._skinny, "Ciphertensor: _matmul_v3_11_wide expects first operand to be a wide matrix"
        assert self.shape == self.actual_shape and self.shape[0] <= self.shape[1], f"Ciphertensor: non skinny matrix does not have apt shape {self.shape}"
        
        other_actual_shape = other.actual_shape
        
        if debug:
            print(f"CP{mpc.pid}:\tUsing M3 (wide) method for ciphertensor matrix multiplication for {self.shape} x {other_actual_shape} operands")
        assert self.shape[1] == other_actual_shape[0], f"Ciphertensor: Invalid matrix dimensions for M3 matmul {self.shape} x {other_actual_shape}"
        assert self._diagonal_contiguous and other._diagonal_contiguous, "Ciphertensor: _matmul_v3_11 expects both operands to be diagonal-contiguous"

        if other._transposed:
            other_t = other.T
        else:
            other_t = other.actual_transpose(mpc)
        assert not self._transposed and not other_t._transposed, "Ciphertensor: diagonal x diagonal matmul operands must not be lazy-transposed"
        assert max(other_t.shape) >= max(self.shape), "Ciphertensor: internal error"

        patch_copy_self = self
        if max(self.shape) < max(other_t.shape):
            # TODO: Write test for this case
            patch_copy_self._diagonal_contiguous = False
            patch_copy_self = patch_copy_self.patch_copy(mpc, max(other_t.shape))
            patch_copy_self._diagonal_contiguous = True

        diag_count = self.shape[0]
        new_diags = [
            patch_copy_self.diagonal(i).mul(mpc, other_t.diagonal(0))
            for i in range(diag_count)]

        for i in range(diag_count):
            if debug:
                print(f"CP{mpc.pid}:\tCiphertensor M3 matmul v11 (wide): {i + 1}/{diag_count} ...")
            
            diag = patch_copy_self.diagonal(i)
            for j in range(1, min(other_t.shape)):
                new_diags[(i - j) % diag_count].iadd(mpc, diag.mul(mpc, other_t.diagonal(j)).irotate(mpc, -j))
        
        new_data = []
        for diag in new_diags:
            new_data.extend(diag._data)
        
        new_ciphertensor = Ciphertensor[ctype](
            _data=new_data,
            shape=patch_copy_self.shape.copy(),
            slots=self.slots,
            _transposed=False,
            _diagonal_contiguous=True,
            _skinny=False)

        if other_actual_shape[1] < patch_copy_self.shape[1]:
            return new_ciphertensor.reduce_add_tiled(mpc, other_actual_shape[1])
        
        return new_ciphertensor

    def _matmul_v3_11_tall(self, mpc, other: Ciphertensor, debug: Static[int]):
        assert self._skinny, "Ciphertensor: _matmul_v3_11_tall expects first operand to be a tall matrix"
        
        self_actual_shape = self.actual_shape
        other_actual_shape = other.actual_shape
        
        if debug:
            print(f"CP{mpc.pid}:\tUsing M3 (tall) method for ciphertensor matrix multiplication for {self_actual_shape} x {other_actual_shape} operands")
        assert self.shape[::-1] == self.actual_shape and self_actual_shape[0] > self_actual_shape[1], f"Ciphertensor: skinny matrix does not have a skinny shape: {self.shape}"
        assert self_actual_shape[1] == other_actual_shape[0], f"Ciphertensor: Invalid matrix dimensions for M3 matmul {self_actual_shape} x {other_actual_shape}"
        assert self._diagonal_contiguous and other._diagonal_contiguous, "Ciphertensor: _matmul_v3_11 expects both operands to be diagonal-contiguous"
        
        if other._transposed:
            other_t = other.T
        else:
            other_t = other.actual_transpose(mpc)
        assert not self._transposed and not other_t._transposed, "Ciphertensor: diagonal x diagonal matmul operands must not be lazy-transposed"

        patch_copy_self = self
        if max(self.shape) < max(other_t.shape):
            # TODO: Write test for this case
            patch_copy_self._diagonal_contiguous = False
            patch_copy_self = patch_copy_self.patch_copy(mpc, max(other_t.shape))
            patch_copy_self._diagonal_contiguous = True
        elif max(other_t.shape) < max(self.shape):
            other_t._diagonal_contiguous = False
            other_t = other_t.patch_copy(mpc, max(self.shape))
            other_t._diagonal_contiguous = True
            
        diag_count = min(self_actual_shape[0], other_actual_shape[1])
        new_diags = {}

        if other._skinny:
            for i in range(min(self.shape)):
                if debug:
                    print(f"CP{mpc.pid}:\tCiphertensor M3 matmul v11 (tall): {i + 1}/{min(self.shape)} ...")
                
                diag = patch_copy_self.diagonal(i)
                for j in range(min(other_t.shape)):
                    diagonal_idx = (i - j) % diag_count
                    partial_diag = diag.mul(mpc, other_t.diagonal(j)).irotate(mpc, diagonal_idx - i)
                    
                    if diagonal_idx not in new_diags:
                        new_diags[diagonal_idx] = partial_diag
                    else:
                        new_diags[diagonal_idx].iadd(mpc, partial_diag)
        
        else:
            debug_counter = 0
            for block_idx in range(diag_count // min(self.shape)):
                for i in range(min(self.shape)):
                    if debug:
                        debug_counter += 1
                        print(f"CP{mpc.pid}:\tCiphertensor M3 matmul v11 (tall): Computing diagonal {debug_counter}/{diag_count} ...")
                    
                    block_offset = block_idx * min(self.shape)
                    diag = patch_copy_self.diagonal(i).rotate(mpc, block_offset)
                    for j in range(min(other_t.shape)):
                        diagonal_idx = (i - j + block_offset) % diag_count
                        partial_diag = diag.mul(mpc, other_t.diagonal(j)).irotate(mpc, -j)
                        
                        if diagonal_idx not in new_diags:
                            new_diags[diagonal_idx] = partial_diag
                        else:
                            new_diags[diagonal_idx].iadd(mpc, partial_diag)
        
        new_data = []
        for i in range(diag_count):
            new_data.extend(new_diags[i]._data)
        
        new_ciphertensor = Ciphertensor[ctype](
            _data=new_data,
            shape=[diag_count, max(max(self.shape), max(other_t.shape))],
            slots=self.slots,
            _transposed=False,
            _diagonal_contiguous=True,
            _skinny=other_actual_shape[1] < self_actual_shape[0])

        return new_ciphertensor
    
    def _matmul_tnt(self, mpc, other, debug: Static[int]):
        """
        Case self is c-contiguous transposed and other is c-contiguous not transposed (either ciphertensor or ndarray).
        """
        self_actual_shape = self.actual_shape
        other_actual_shape = other.shape
        if debug: print(f"CP{mpc.pid}:\tUsing c-contig transposed-non-transposed method for ciphertensor matrix multiplication for {self_actual_shape} x {other_actual_shape} operands")

        if self.shape[1] > other.shape[1]:
            other = other.patch_copy(mpc, self.shape[1])

        if isinstance(other, ndarray):
            other_cipher = Ciphertensor[Plaintext].enc(mpc, other)
        elif isinstance(other, Ciphertensor):
            other_cipher = other
        else:
            compile_error("Ciphertensor: invalid input for _matmul_tnt")
        
        assert self_actual_shape[1] == other_cipher.shape[0], f"Ciphertensor: Invalid matrix dimentions for M3 matmul {self_actual_shape} x {other_cipher.shape}"
        assert not self._diagonal_contiguous and not other_cipher._diagonal_contiguous, "Ciphertensor: _matmul_tnt expects operand to be c-contiguous"
        assert self._transposed and not other_cipher._transposed, "Ciphertensor: _matmul_tnt expects first operand to be transposed and second operand not to be transposed"

        if self.shape[1] < other_cipher.shape[1]: patch_copy_self = self.patch_copy(mpc, other_cipher.shape[1])
        else: patch_copy_self = self.copy()

        semi_slot = patch_copy_self.shape[1] < self.slots >> 1
        # No need to do actual rotation downstream if data size is less than slots // 2
        # Patch copy self to double size
        if semi_slot:
            patch_copy_self = patch_copy_self.patch_copy(mpc, patch_copy_self.shape[1] << 1)
            # Assume diagonals are trailed by zeros and pad them lazily by expanding shape
            other_cipher.shape[1] <<= 1
        
        mpc.mhe.refresh(patch_copy_self._data, self._is_broadcast, min_level_distance=2)
        if isinstance(other_cipher, Ciphertensor[Ciphertext]):
            mpc.mhe.refresh(other_cipher._data, other_cipher._is_broadcast)
        
        new_data = []
        debug_counter = 0
        diagonals_count = min(self_actual_shape[0], other_actual_shape[1])
        for d_idx in range(diagonals_count):
            if debug:
                debug_counter += 1
                print(f"CP{mpc.pid}:\tCiphertensor M3 matmul (tnt): {debug_counter}/{diagonals_count} ...")
            
            rotated_self = patch_copy_self.copy()
            if semi_slot and d_idx:
                mpc.mhe.irotate(rotated_self._data, d_idx)
            elif d_idx:
                rotated_self.irotate(mpc, d_idx)

            new_diagonal = rotated_self._get_rows_raw(0).mul(mpc, other_cipher._get_rows_raw(0))
            for i in range(1, other_cipher.shape[0]):
                new_diagonal.iadd(mpc, rotated_self._get_rows_raw(i).mul(mpc, other_cipher._get_rows_raw(i)))
                
            new_data.extend(new_diagonal._data)
        
        if semi_slot:
            patch_copy_self.shape[1] >>= 1
            other_cipher.shape[1] >>= 1
        
        result_shape = [self_actual_shape[0], other_actual_shape[1]]

        _transposed = False
        _diagonal_contiguous = False
        if result_shape[1] == 1:
            result_shape = result_shape[::-1]
            _transposed = True
        elif result_shape[0] > 1:
            _diagonal_contiguous = True
        
        return Ciphertensor[ctype](
                _data=new_data,
                shape=result_shape,
                slots=self.slots,
                _transposed=_transposed,
                _diagonal_contiguous=_diagonal_contiguous,
                _skinny=(other_actual_shape[1] < self_actual_shape[0]) and _diagonal_contiguous)

    def _handle_plaintext_case(self, mpc, op) -> Ciphertensor[Plaintext]:
        raise NotImplementedError("Plaintext univariate operations not implemented yet. Decoding is too expensive.")
        return Ciphertensor[Plaintext]()
    
    def _handle_plaintext_case(self, mpc, other, op) -> Ciphertensor[Plaintext]:
        # # TODO: Read dtype on decoding (T) from other (add dtype static to Ciphertensor class)
        # if not isinstance(other, Ciphertensor):
        #     return Ciphertensor[Plaintext].enc(mpc, op(self.decode(mpc, T=float), other))
        # elif isinstance(other.ctype, Plaintext):
        #     return Ciphertensor[Plaintext].enc(mpc, op(self.decode(mpc, T=float), other.decode(mpc, T=float)))
        # else:
        #     compile_error("Invalid type for plaintext case elem-wise operand")
        raise NotImplementedError("Plaintext-plaintext elem-wise operations not implemented yet. Decoding is too expensive.")
        return Ciphertensor[Plaintext]()
    
    def _check_other_operand_elem_wise(self, mpc, other):
        enc_mode = ENC_DIAG if self._diagonal_contiguous else ENC_ROW
        if isinstance(other, Ciphertensor):
            # TODO: Temp and ad-hoc solution for self._diagonal_contiguous ^ other._diagonal_contiguous case.
            # Check for a better way.
            pt = other
            if self._diagonal_contiguous ^ other._diagonal_contiguous:
                if other._diagonal_contiguous:
                    pt = other.get_actual(mpc)
                else:
                    self.iget_actual(mpc)

            # TODO: Temp and ad-hoc solution for self._transposed ^ other._transposed case.
            # Check for a better way.
            # It can be improved at lease for the case where both ciphers are cyclic diagonal.
            if self._transposed ^ pt._transposed:
                pt = pt.get_actual(mpc) if pt._transposed else pt.actual_transpose(mpc)
                pt._transposed = self._transposed
            
            pt = pt.local_broadcast(mpc, self.shape)
        elif isinstance(other, ndarray):
            operand = other.T if self._transposed else other
            pt = Ciphertensor[Plaintext].enc(mpc, operand, encoding=enc_mode)
            pt._transposed = self._transposed
        elif isinstance(other, List):
            operand = other.transpose() if self._transposed else other
            pt = Ciphertensor[Plaintext].enc(mpc, array(operand), encoding=enc_mode)
            pt._transposed = self._transposed
        elif isinstance(other, int) or isinstance(other, float):
            ptensor = Ciphertensor[Plaintext].enc_patch_copy(mpc, other, self.shape)
            ptensor._transposed = self._transposed
            ptensor._diagonal_contiguous = self._diagonal_contiguous
            pt = ptensor
        else:
            compile_error("Invalid operand for Ciphertensor")

        assert self.shape == pt.shape, f"Ciphertensor.elem_wise_op: Shapes mismatch: {self.shape} != {pt.shape}"
        return pt
    
    def _reset_chunk_size(self):
        self._chunk_size = 1 if len(self.shape) <= 1 else Ciphertensor._count(self.cipher_shape[1:])

    @staticmethod
    def _concat_1_dim_raw(mpc, first: Ciphertensor[ctype], other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        assert first.ndim == other.ndim == 1, "Ciphertensor: invalid dimensions form 1-dimensional concat"
        slots = first.slots
        offset = first.shape[0] % slots
        _data = []
        
        _data.extend(first._data.copy())
        if offset == 0:
            _data.extend(other._data)
        elif other.shape[0] + offset < slots:
            # TODO: Potential problem if first has non-zero data beyond first.shape[0]
            rotated_cipher = mpc.mhe.crypto_params.evaluator.rotate_new(other._data[0], slots - offset)
            mpc.mhe.iadd([_data[-1]], [rotated_cipher])
        else:
            rotated_other = other.shift(mpc, slots - offset)
            mask = mpc.mhe.enc_vector([(1.0 if i < offset else 0.0) for i in range(slots)], T=Plaintext)
            mpc.mhe.imul([_data[-1]], mask)
            # TODO: mpc.mhe.iadd is buggy (possibly due to different scales/levels of the operands)
            mpc.mhe.iadd([_data[-1]], [rotated_other._data[0]])
            _data.extend(rotated_other._data[1:])

            if other.shape[0] % slots <= slots - offset:
                _data.pop()

        return Ciphertensor[ctype](
            _data=_data,
            shape=[first.shape[0] + other.shape[0]],
            slots=slots)
    
    def _iconcat_axis_1_raw(self, mpc, other):
        assert self.shape[0] == other.shape[0], "Ciphertensor: shapes missmatch while concatenating along axis 1"
        
        _data = []
        for i in range(self.shape[0]):
            self_row = self._get_rows_raw(i)
            other_row = other._get_rows_raw(i)
            _data.extend(Ciphertensor._concat_1_dim_raw(mpc, self_row, other_row)._data)
        
        self._data = _data
    
    def _getitem(self, mpc, indices) -> Ciphertensor[ctype]:
        if isinstance(indices, tuple) or self.ndim > 1:
            tuple_indices, _ = self._coerce_tuple_indices(indices)
            
            pack_dim = False
            if isinstance(indices, int):
                pack_dim = True
            elif isinstance(indices, tuple):
                if isinstance(indices[0], int):
                    pack_dim = not self._transposed
                elif isinstance(indices[1], int):
                    pack_dim = self._transposed
            
            return self._get_slices_raw(mpc, tuple_indices, pack_dim)
        
        assert self.ndim == 1, f"Ciphertensor: invalid indices for 1-dimensional getitem: {indices}"
        return self._getitem_1_dim(mpc, indices)
    
    def _getitem_1_dim(self, mpc, indices) -> Ciphertensor[ctype]:
        assert self.ndim == 1, "Ciphertensor: should be 1-dimensional in 1-dim getitem"
        assert not self._diagonal_contiguous, "Not implemented yet: getitem on diagonal-contiguous ciphertensor"
        start, stop = self._adjust_col_indices(indices)
        
        if stop - start == 0:
            return Ciphertensor[ctype](slots=self.slots, _transposed=self._transposed)
        if start == 0 and stop == self.shape[-1]:
            return self
        
        # TODO: Bugfix required: mask_range below requires bootstrap check.
        # Some parties may not reach it because of the checks above. This causes deadlock.
        # Use mask_range_noboot instead and then change methods upstream to use manual bootstraps and no MPP aligners.

        start_cipher_idx = start // self.slots
        stop_cipher_idx = (stop - 1) // self.slots

        start_cipher = self._data[start_cipher_idx]
        upper_limit = stop % self.slots if start_cipher_idx == stop_cipher_idx else self.slots
        masked_start_cipher = mpc.mhe.mask_range(start_cipher, start % self.slots, upper_limit)
        _data = [masked_start_cipher]
        
        if start_cipher_idx != stop_cipher_idx:
            # stop_cipher = self._data[stop_cipher_idx]
            # masked_stop_cipher = mpc.mhe.mask_range(stop_cipher, 0, stop % self.slots)
            # inbetween_ciphers = self._data[start_cipher_idx + 1:stop_cipher_idx - 1].copy()
            # _data.extend(inbetween_ciphers)
            # _data.append(masked_stop_cipher)
            raise NotImplementedError("Bugfix required: getting from 1-dimensonal multicipher ciphertensor")

        if start % self.slots: mpc.mhe.irotate(_data, start % self.slots)
        
        return Ciphertensor[ctype](
            _data=_data,
            shape=[stop - start],
            slots=self.slots,
            _transposed=self._transposed)
    
    def _get_rows_raw(self, indices) -> Ciphertensor[ctype]:
        assert self.ndim > 1, "Ciphertensor: cannot get rows from one-dimensional ciphertensor"
        
        shape, start, stop = self._adjust_row_indices(indices)
        
        return Ciphertensor[ctype](
            _data=self._data[start * self._chunk_size:stop * self._chunk_size],
            shape=shape,
            slots=self.slots,
            _transposed=False if isinstance(indices, int) else self._transposed)
    
    def _get_rows_nil_ideal(self, indices) -> Ciphertensor[ctype]:
        assert self.ndim > 1, "Ciphertensor: cannot get rows from one-dimensional ciphertensor"
        
        _data = []
        _, start, stop = self._adjust_row_indices(indices)

        for _ in range(start):
            _data.append(ctype.nil_ideal())
        
        _data.extend(self._data[start * self._chunk_size:stop * self._chunk_size])

        for _ in range(stop, len(self._data)):
            _data.append(ctype.nil_ideal())
        
        return Ciphertensor[ctype](
            _data=_data,
            shape=self.shape.copy(),
            slots=self.slots,
            _transposed=self._transposed)
    
    def _get_slices_raw(self, mpc, indices: Tuple[slice, slice], pack_dim: bool = False) -> Ciphertensor[ctype]:
        rs, cs = indices
        c_start, c_stop, _, _ = cs.adjust_indices(self.shape[-1])
        
        row_sliced_ctensor = self._get_rows_raw(rs)

        new_ciphertensor = Ciphertensor[ctype](
            shape=[0, c_stop - c_start],
            slots=self.slots)
        
        for row in row_sliced_ctensor._raw_iter():
            new_ciphertensor.append(row._getitem_1_dim(mpc, cs))
        
        if new_ciphertensor.ndim > 1 and new_ciphertensor.shape[0] == 1 and pack_dim:
            new_ciphertensor.shape = new_ciphertensor.shape[1:]
        
        new_ciphertensor._transposed = self._transposed
        return new_ciphertensor

    def _setitem(self, mpc, indices, value: Ciphertensor[ctype]):
        if isinstance(indices, tuple) or self.ndim > 1:
            tuple_indices, adjusted_value = self._coerce_tuple_indices(indices, value)
            return self._set_slices_raw(mpc, tuple_indices, adjusted_value)
        
        assert self.ndim == 1, f"Ciphertensor: invalid indices for 1-dimensional setitem: {indices}"
        return self._setitem_1_dim(mpc, indices, value)
    
    def _setitem_1_dim(self, mpc, indices, value: Ciphertensor[ctype]):
        assert self.ndim == value.ndim == 1, "Ciphertensor: operands should be 1-dimensional in 1-dim setitem"
        
        start, stop = self._adjust_col_indices(indices)
        assert value.shape == [stop - start], "Ciphertensor: 1-dim setitem value should have a single element"

        if stop - start == 0:
            return
        if start == 0 and stop == self.shape[-1]:
            self._data = value._data
            return
        
        start_offset = start % self.slots
        addend_data = value._data.copy()
        
        if start_offset:
            if start_offset + value.shape[0] > self.slots:
                addend_data = mpc.mhe.shift(addend_data, self.slots - start_offset)
            else:
                mpc.mhe.irotate(addend_data, self.slots - start_offset)

        start_cipher_idx = start // self.slots
        stop_cipher_idx = (stop - 1) // self.slots

        start_cipher = self._data[start_cipher_idx]
        upper_limit = stop % self.slots if start_cipher_idx == stop_cipher_idx else self.slots
        masked_start_cipher = mpc.mhe.mask_range(start_cipher, start % self.slots, upper_limit, complement=True)
        
        mpc.mhe.iadd([masked_start_cipher], addend_data[:1])
        self._data[start_cipher_idx] = masked_start_cipher

        if start_cipher_idx != stop_cipher_idx:
            stop_cipher = self._data[stop_cipher_idx]
            masked_stop_cipher = mpc.mhe.mask_range(stop_cipher, 0, stop % self.slots, complement=True)
            mpc.mhe.iadd([masked_stop_cipher], addend_data[-1:])
            self._data[stop_cipher_idx] = masked_start_cipher
            
            assert stop_cipher_idx - start_cipher_idx == len(addend_data), f"Ciphertensor: Cannot set {len(addend_data)} ciphers into {stop_cipher_idx - start_cipher_idx} slots"
            self._data[start_cipher_idx + 1:stop_cipher_idx - 1] = addend_data[1:-1]

    def _set_rows_raw(self, indices, value: Ciphertensor[ctype]):
        assert self.ndim > 1, "Ciphertensor: cannot set rows to one-dimensional ciphertensor"
        assert not self._diagonal_contiguous, "Not implemented yet: setitem on diagonal-contiguous ciphertensor"
        
        if isinstance(indices, int):
            assert self.shape[1:] == value.shape, f"Ciphertensor: incompatible shapes in n-dim setitem: {self.shape} and {value.shape}"
        elif isinstance(indices, slice):
            assert self.shape[1:] == value.shape[1:], f"Ciphertensor: incompatible shapes in n-dim setitem: {self.shape} and {value.shape}"
        else:
            compile_error("Ciphertensor: invalid indices")
        
        _, start, stop = self._adjust_row_indices(indices)
        
        assert (stop - start) * self._chunk_size == len(value._data), f"Ciphertensor: cannot set {len(value._data)} ciphers into slice of size {(stop - start)} (and actual size: {(stop - start) * self._chunk_size})"
        self._data[start * self._chunk_size:stop * self._chunk_size] = value._data

    def _set_slices_raw(self, mpc, indices: Tuple[slice, slice], value: Ciphertensor[ctype]):
        assert value.ndim > 1, "Ciphertensor: invalid set-value dimension --- needs to be multidimensional to set int into sliced ciphertensor"
        
        rs, cs = indices
        r_start, r_stop, _, _ = rs.adjust_indices(self.shape[0])
        c_start, c_stop, _, _ = cs.adjust_indices(self.shape[1])

        if c_start == 0 and c_stop == self.shape[1]:
            self._set_rows_raw(rs, value)
            return

        value_idx = 0
        for i in range(r_start, r_stop):
            row = self._get_rows_raw(i)
            row._setitem_1_dim(mpc, cs, value._get_rows_raw(value_idx))
            self._set_rows_raw(i, row)
            value_idx += 1
    
    def _coerce_tuple_indices(self, indices, ctensor: Ciphertensor[ctype] = Ciphertensor[ctype]()) -> Tuple[Tuple[slice, slice], Ciphertensor[ctype]]:        
        whole_slice = slice(start=None, stop=None, step=1)
        if isinstance(indices, int):
            one_slice = slice(start=indices, stop=indices+1, step=1)
            tuple_indices = (one_slice, whole_slice)
        elif isinstance(indices, slice):
            tuple_indices = (indices, whole_slice)
        elif isinstance(indices, Tuple[slice, slice]):
            tuple_indices = indices
        elif isinstance(indices, Tuple[int, slice]):
            rs, cs = indices
            one_slice = slice(start=rs, stop=rs + 1, step=1)
            tuple_indices = (one_slice, cs)
        elif isinstance(indices, Tuple[slice, int]):
            rs, cs = indices
            one_slice = slice(start=cs, stop=cs + 1, step=1)
            tuple_indices = (rs, one_slice)
        elif isinstance(indices, Tuple[int, int]):
            rs, cs = indices
            one_rs_slice = slice(start=rs, stop=rs + 1, step=1)
            one_cs_slice = slice(start=cs, stop=cs + 1, step=1)
            tuple_indices = (one_rs_slice, one_cs_slice)
        else:
            compile_error("Ciphertensor: invalid indices")

        tuple_indices = tuple_indices[::-1] if self._transposed else tuple_indices
        
        if ctensor:
            assert ctensor.ndim, "Ciphertensor: invalid ndim"
            if ctensor.ndim != 1:
                assert not (self._transposed ^ ctensor._transposed), "Not implemented yet: setting transposed ciphertensor"

            if ctensor.ndim == 1:
                assert not ctensor._transposed, "Not implemented yet: setting 1-dimensional transposed ciphertensor"
                ctensor_cp = ctensor.copy(shallow=True)
                ctensor_cp.shape.insert(0, 1)
                return tuple_indices, ctensor_cp
        
        return tuple_indices, ctensor
    
    def _adjust_row_indices(self, indices):
        assert self.ndim > 1, "Ciphertensor: cannot adjust row-indices of 1-dim ciphertensor"
        
        if isinstance(indices, int):
            start = indices
            stop = indices + 1
            shape = self.shape[1:].copy()
        elif isinstance(indices, slice):
            start, stop, _, _ = indices.adjust_indices(self.shape[0])
            shape = []
            if stop - start:
                shape = self.shape.copy()
                shape[0] = stop - start
        else:
            compile_error("Ciphertensor: invalid indices for row-wise adjustment")
        
        return shape, start, stop
    
    def _adjust_col_indices(self, indices):
        assert self.ndim == 1, "Ciphertensor: can adjust row-indices of 1-dim ciphertensor only"
        
        if isinstance(indices, int):
            start = indices
            stop = indices + 1
        elif isinstance(indices, slice):
            start, stop, _, _ = indices.adjust_indices(self.shape[0])
        else:
            compile_error("Ciphertensor: invalid indices for col-wise adjustment")
        
        return start, stop


@extend
class ndarray:
    def __matmul__(self, other: Ciphertensor):
        raise NotImplementedError("Cannot matmul by secure value without IR passes enabled")
        return type(other)()  # To avoid compiler error
    
    def __add__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        raise NotImplementedError("Cannot add by secure value without IR passes enabled")
    
    def __sub__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        raise NotImplementedError("Cannot subtract by secure value without IR passes enabled")
    
    def __mul__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        raise NotImplementedError("Cannot multiply by secure value without IR passes enabled")
    
    def add[ctype](self, mpc, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other.add(mpc, self)
    
    def sub[ctype](self, mpc, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other.sub(mpc, self).neg(mpc)
    
    def mul[ctype](self, mpc, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other.mul(mpc, self)
    
    def matmul[ctype](self, mpc, other: Ciphertensor[ctype], debug: Static[int] = DEBUG) -> Ciphertensor[ctype]:
        if isinstance(ctype, Plaintext):
            return Ciphertensor[Plaintext].enc(mpc, self @ other.decode(mpc, T=T))
        
        return self._switch_matmul_by_cost(mpc, other, debug)
    
    def get_matmul_cost(self, other: Ciphertensor) -> float:
        # Return _matmul_v2_ cost for now
        return other.T.get_matmul_cost(self.T) + MHE_MPC_SWITCH_COST_ESTIMATE * Ciphertensor._count_ciphers((other.shape[1], self.shape[0]), other.slots)
    
    def _switch_matmul_by_cost[ctype](self, mpc, other: Ciphertensor[ctype], debug: Static[int]) -> Ciphertensor[ctype]:
        # TODO: Implement cost calculation
        return self._matmul_via_transposing(mpc, other, lazy=True, debug=debug)
    
    @staticmethod
    def _get_matmul_v2_cost(first: ndarray, other: Ciphertensor, transposed=False):
        slots = other.slots
        self_shape = first.shape[::-1] if transposed else first.shape
        other_shape = other.shape[::-1] if transposed else other.shape

        cost_per_cipher = (self_shape[1] + slots - 1) // slots
        self_size = self_shape[0] * self_shape[1]

        return (cost_per_cipher * self_size * (HE_MUL_COST_ESTIMATE + HE_ENC_COST_ESTIMATE * ((other_shape[1] + slots - 1) // slots)))
    
    def _matmul_v1[ctype](self, mpc, other: Ciphertensor[ctype], debug: Static[int]) -> Ciphertensor[ctype]:
        if other._transposed:
            return Ciphertensor[Plaintext].enc(mpc, self)._matmul_v1(mpc, other, debug)

        assert self.ndim == other.ndim == 2, f"Ciphertensor: at least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other.shape}. Ciphertensor matmul supports only matrices at the moment"
        assert self.shape[1] == other.shape[0], f"Ciphertensor: invalid matrix dimentions for reversed matmul: {self.shape} x {other.shape}"

        new_ciphertensor = Ciphertensor[ctype].zeros(mpc, [self.shape[0], other.shape[1]])

        debug_counter = 1
        for self_column, other_row in zip(self.T, other):
            if debug: print(f"Ciphertensor reversed matmul: computing row {debug_counter}/{self.shape[1]} ...")
            for i, self_elem in enumerate(self_column):
                new_ciphertensor._get_rows_raw(i).iadd(mpc, other_row.mul(mpc, self_elem))
            debug_counter += 1
        
        return new_ciphertensor

    def _matmul_via_transposing[ctype](self, mpc, other: Ciphertensor[ctype], lazy: bool, debug: Static[int]) -> Ciphertensor[ctype]:
        assert self.ndim == other.ndim == 2, f"Ciphertensor: at least one of the tensors is not a matrix. Self shape: {self.shape}, other shape: {other.shape}. Ciphertensor matmul supports only matrices at the moment"
        # A @ B = (B.T @ A.T).T
        result = other.T.matmul(mpc, self.T, debug)
        return result.T if lazy else result.actual_transpose(mpc)
    
    def _matmul_v2[ctype](self, mpc, other: Ciphertensor[ctype], debug: Static[int]):
        """
        M2 method from https://arxiv.org/pdf/2304.00129.pdf
        """
        self_shape = self.shape
        other_shape = other.shape
        if debug: print(f"CP{mpc.pid}:\tUsing M2 method for ciphertensor matrix multiplication for {self_shape} x {other_shape} operands")
        assert self_shape[1] == other_shape[0], f"Ciphertensor: invalid matrix dimentions for M2 matmul {self_shape} x {other_shape}"
        assert not other._transposed, "Ciphertensor: ciphertensors should not be lazily transposed prior to M2 matrix multiplication"
        assert not other._diagonal_contiguous, "Ciphertensor: cannot apply M1 matrix multiplication method to diagonal-contiguous ciphertensors"

        new_ciphertensor = Ciphertensor[ctype].zeros(mpc, [self_shape[0], other_shape[1]])

        for i in range(self_shape[0]):
            if debug: print(f"CP{mpc.pid}:\tndarray M2 matmul: Computing row {i + 1}/{self_shape[0]} ...")
            new_row = new_ciphertensor._get_rows_raw(i)
            self_row = self[i]
            for j in range(self_shape[1]):
                other_elem_duplicated = self_row.getitemdup(j, other_shape[1])
                new_row.iadd(mpc, other._get_rows_raw(j).mul(mpc, other_elem_duplicated))
        
        return new_ciphertensor


@extend
class int:
    def __add__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other + self
    
    def __sub__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return -other + self
    
    def __mul__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other * self
    
    def __truediv__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        raise NotImplementedError("Cannot divide by secure value without IR passes enabled.")


@extend
class float:
    def __add__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other + self
    
    def __sub__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return -other + self
    
    def __mul__[ctype](self, other: Ciphertensor[ctype]) -> Ciphertensor[ctype]:
        return other * self


ndcipher = Ciphertensor[Ciphertext]
ndplain = Ciphertensor[Plaintext]
